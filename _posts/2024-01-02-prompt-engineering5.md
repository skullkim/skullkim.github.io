---
layout:       post
title:        "Chapter 5. LLM의 구조와 원리를 고려한 기법"
author:       "yunki kim"
header-style: text
catalog:      true
tags:
- 도서
- 프롬프트 엔지니어링
- AI
---

# 1. AI를 사람처럼 대하라

- 이전 장에서 살펴본 기법은 AI를 컴퓨터나 기계로 바라보는 관점을 가진다. 이제 AI를 하나의 인격체를 다루는 것처럼 행동해 원하는 결과를 얻는 방법을 알아보자.

# 2. AI 행동 방침을 하다라하라, 규칙 부여 프롬프트

- LLM은 어텐션이 있기에 과거에 사용자와 나누었던 대화를 참고해서 현재의 답변을 생성한다. 즉, 한 번 규칙을 입력해두면 이후에는 그 규칙을 지키며 답변을 생성할 수 있다.

# 3. 주도권을 AI에 넘기다, 질의 응답 역전

- 사용자가 질문하고 AI가 답하는 기본적인 구조에서 대화 주도권은 인간에게 있다. 즉, 대화의 흐름과 지적 수준이 사용자에 따라 결정된다. 때문에 아무리 똑똑한 AI여도 100% 활용하지 못하는 경우가 발생한다. 이를 방지하기 위해 대화 주도권을 AI에게 넘겨버리고, 사용자가 대화의 흐름을 따라 행동하는 방법이 존재한다.

![AI Q&A](/img/2024-01-02-prompt-engineering5/img.png)

- 이렇게 AI가 질문을 던졌을 때, 사용자는 다음과 같이 대답할 수 있다.
    - 떠넘기기: “글쎄, 나한테는 어려운 질문인 것 같네. 너는 어떻게 생각해?”
        - 나의 지식으로 작성해야 할 문장의 작성을 AI에게 떠넘긴다. AI가 자신의 레이턴트 스페이스 상의 정보를 토대로 논리를 작성하기에 사용자가 전혀 모르는 분야의 주장도 설계할 수 있다.
    - 첨삭 요청: 나는 XXX라고 생각하는데, 혹시 이런 의견을 조금 더 보완하려면 어떻게 해야 할까?
        - AI의 피드백을 통해 논리의 방향 조정, 부족한 정보 보충을 해서 사용자가 가진 지식과 지성의 한계를 극복할 수 있다.
    - 설명 요구: 나한테는 어려운 질문이야. 그 질문에 답하는 데 도움이 될만한 지식을 제공해 줄래?
        - LLM과 특정 토픽을 주제로 대화를 나누는 도중 주제와 관련된 질문을 하면 AI의 답변 성능이 급격히 높아진다.
        - 관심 없던 분야의 토픽을 빠르게 살펴볼 수 있지만 할루시네이션 발생 우려가 있기에 키워드를 확인하는 용도로만 사용해야 한다.
    - 쟁점 추가 요청: 혹시 다른 쟁점들도 몇 개 뽑아줄 수 있어?
        - 낯선 분야를 빠르게 조사해야 하는 상황에서 가이드라인을 확보할 수 있는 전략이다.
        - GPT-4는 해당 사안이 쟁점이 된 이유까지 설명해 준다. 따라서 이유가 논리적인지를 검토하는 것만으로도 할루시네이션을 어느 정도 회피할 수 있다.

# 4. 어텐션의 기본 역량, 독해

- LLM은 구조적으로 요약과 맥락 이해에 특화된 모듈이 많이 포함된 AI이다. 때문에 뛰어난 독해 역량을 갖고 있다. 이런 독해 역량을 이용해 다음과 같은 일을 수행할 수 있다.
    - 요약
    - 핵심 문장 추출
    - 지문을 토대로 새로운 논리/질문/생각 도출하기
        - 인사이트를 요청하거나 미래를 예측하는 도구로 활용한다.
    - 지문 분석 요청하기

# 5. 어텐션의 놀라운 효능, 논리적 추론

- LLM은 “가끔 틀리는 검색엔진” 정도가 아니다. 강력한 논리 추론 능력을 가지고 있다. 논리적 추론 분야에서 이미 AI는 대부분의 인간을 앞서고 있다.

# 6. 레이턴트 스페이스에 남은 정보와 어텐션, 유사성 분석

- 입력 프롬프트에서 제시된 내용을 토대로 정보의 유사성을 검토하는 작업이다.
- 유사성 분석에선 할루시네이션으로 인해 AI가 잘못된 정보를 토대로 유사성 분석을 하게 될 수 있다. 할루시네이션을 방지할 수 있는 방법은 크게 두 가지가 있다.
    - 외부 정보를 참고할 수 있는 AI 사용
        - 외부 정보를 참고하고, 이를 토대로 답변하는 AI는 상대적으로 할루시네이션이 발생할 가능성이 낮다. 예를 들어 바드는 구글 검색 결과를 참고하고 GPT-4는 being의 검색 결과를 참고한다.
    - 정보를 직접 제공
        - 정확하다고 판단되는 정보를 직접 제공하고 이를 토대로 유사성 분석 작업을 진행할 수 있다. 그러면 할루시네이션이 전혀 없는, 신뢰할 수 있는 답변을 받을 수 있다.

# 7. 생성형 사전 훈련의 흔적, 문법 적합성 판단

- LLM은 생성형 사전 훈련(Generative Pre-training)을 수행하는 과정에서 ‘단어가 배치되는 순서’에 대한 정보를 대량 습득하게 된다. 단어와 단어의 배열 순서는 문법이라는 특정 규칙을 따른다.
- AI가 학습하는 최소한의 언어 덩어리를 토큰(token)이라 한다. AI에게 텍스트를 입력하면 정해진 규칙에 따라 텍스트가 토큰으로 쪼개져서 순서대로 입력받게 된다.

출처 - [프롬프트 엔지니어링](https://product.kyobobook.co.kr/detail/S000209512470)