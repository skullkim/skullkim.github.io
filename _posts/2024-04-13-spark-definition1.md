---
layout:       post
title:        "1. 아파치 스파크란"
author:       "yunki kim"
header-style: text
catalog:      true
tags:
- 도서
- apache spark
- 스파크 완벽 가이드
---
아파치 스파크는 빅데이터를 위한 통합 컴퓨팅 엔진이자 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합이다.
![spark function](/img/2024-04-13-spark-definition1/image.png)

# 1 아파치 스파크의 철할

## 1.1 통합

스파크 핵심 목표는 ‘빅데이터 애플리케이션 개발에 필요한 통합 플랫폼을 제공’하는 것이다. 통합이라는 특성은 다음과 같은 점에서 잘 나타난다.

- 다양한 데이터 분석 작업을 같은 연산 엔진과 일관성있는 조합형 API로 수행할 수 있다.
- 직접 스파크 기반 라이브러리를 만들 수 있다.
- 스파크 API는 애플리케이션에서 여러 라이브러리 기능을 조합해 성능을 향상시킨다.(ex - 여러 단계를 하나로 통합시킨다)

통합이라는 특성과 처리 능력을 합하면 대화형 분석과 애플리케이션에 필요한 플랫폼을 얻을 수 있다.

## 1.2 컴퓨팅 엔진

스파크가 제공하는 기능 범위는 컴퓨팅 엔진에 국한되어 있다. 때문에 데이터를 저장할 별도의 영구 저장소를 필요로 한다. 또 한, 데이터 저장 위치를 가리지 않으므로 데이터 이동으로 인한 비용을 절감할 수 있다.

컴퓨팅 엔진에만 초점을 맞췄다는 점은 기존 빅데이터 플랫폼과의 차별점 중 하나이다. 하둡의 경우 HDFS와 컴퓨팅 시스템(맵리듀스)을 분리해 사용하기 어렵다.

## 1.3 라이브러리

스파크는 표준 라이브러리, 오픈소스 커뮤니티에서 서드파티 패키지 형태로 제공하는 다양한 외부 라이브러리를 지원한다.

![spark library](/img/2024-04-13-spark-definition1/img1.png)

# 2. 스파크의 등장 배경

예전에는 대규모 데이터 처리를 프로세서 성능에 의존했다. 하지만, 단일 프로세서 성능 향상폭이 둔화됨에 따라 병렬처리가 필요해졌다. 데이터 저장과 수집에 필요한 비용도 꾸준히 낮아지고 있다.

데이터 수집 비용은 낮아졌지만 처리할 데이터 양은 많아졌다. 소프트웨어 성능이 더는 향상되지 않고 전통적인 데이터 처리 프로그래밍 모델이 힘을 발휘하지 못하면서 문제 해결을 위한 새로운 프로그래밍 모델인 스파크가 탄생했다.

출처 - [스파크 완벽 가이드](https://product.kyobobook.co.kr/detail/S000001810100)